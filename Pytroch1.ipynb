{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytroch1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepds/pytorch/blob/master/Pytroch1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM2AUgSRkm45",
        "colab_type": "text"
      },
      "source": [
        "### 1. Сверточные слои\n",
        "Изображение, три канала, сверточный фильтр, свертка, карта активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZclyRWnKBv",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=12KxN_oIhwNlsTgr-LVKwlnNHwSnzBmeU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl4OKg7coIrj",
        "colab_type": "text"
      },
      "source": [
        "Два способа вычисления свертки в Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJfOlLVtkqfA",
        "colab_type": "code",
        "outputId": "625e4610-cbf5-4c5d-8d14-5294f9fa1ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "image = torch.rand(16,3,32,32)\n",
        "conv_filter = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=1, padding=0)\n",
        "out_feature = conv_filter(image)\n",
        "\n",
        "print(out_feature.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJrjYgyqnBYN",
        "colab_type": "code",
        "outputId": "d1d399e0-0dad-4875-9292-43d31c092a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "image = torch.rand(16, 3, 32, 32)\n",
        "filter = torch.rand(1, 3, 5, 5)\n",
        "out_feat_f = F.conv2d(image, filter, stride=1, padding=0)\n",
        "\n",
        "print(out_feat_f.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X11Trg9oo6cX",
        "colab_type": "text"
      },
      "source": [
        "Оператор свертки - путь ООП\n",
        "Давайте начнем эту главу с помощью оператора свертки из пакета torch.nn. Вы собираетесь создать случайный тензор, который будет представлять ваше изображение, и случайные фильтры для свертывания изображения. Затем вы примените эти изображения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqm8Sq20oGkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create 10 random images of shape (1, 28, 28)\n",
        "images = ____.____(____, ____, ____, ____)\n",
        "\n",
        "# Build 6 conv. filters (out_channels=6)\n",
        "conv_filters = ____.____.____(____=____, ____=____, ____=____, ____=____, ____=____)\n",
        "\n",
        "# Convolve the image with the filters \n",
        "output_feature = ____(____)\n",
        "print(output_feature.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kw-pFquqClJ",
        "colab_type": "text"
      },
      "source": [
        "Оператор свертки - Функциональный способ\n",
        "В то время как я и большинство практикующих PyTorch любят пакет torch.nn (ООП), другие практикующие предпочитают строить модели нейронных сетей более функциональным способом, используя torch.nn.functional. Что еще более важно, можно смешивать понятия и использовать обе библиотеки одновременно (мы уже делали это в предыдущей главе). Вы собираетесь построить ту же нейронную сеть, которую вы создали в предыдущем упражнении, но на этот раз, используя функциональный способ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrgPM_WtqK7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create 10 random images\n",
        "image = ____.____(____, ____, ____, ____)\n",
        "\n",
        "# Create 6 filters\n",
        "filters = ____.____(____, ____, ____, ____)\n",
        "\n",
        "# Convolve the image with the filters\n",
        "output_feature = ____.____(____, ____, ____=____, ____=____)\n",
        "print(output_feature.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt-B26zQq2cf",
        "colab_type": "text"
      },
      "source": [
        "### 2. Субдискретизующие слови (Pooling)\n",
        "\n",
        "Отбор признаков и понижение размерности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZE5IPWurnH1",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1iDS9PSxNC7Yzp2QYjed9jW7NxosQfkPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6mLRPirq5vk",
        "colab_type": "code",
        "outputId": "4b92f041-38f4-4942-c1e5-14ebf0e415ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "im = torch.Tensor([[[3,1,3,5],[6,0,7,9],[3,2,1,4],[0,2,4,3]]])\n",
        "\n",
        "max_pooling = torch.nn.MaxPool2d(2)\n",
        "output_feature = max_pooling(im)\n",
        "\n",
        "print(output_feature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[6., 9.],\n",
            "         [3., 4.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmDwGIKLrl2J",
        "colab_type": "code",
        "outputId": "883709f2-143a-446c-afdf-8d10ec97c61e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "im = torch.Tensor([[[3,1,3,5],[6,0,7,9],[3,2,1,4],[0,2,4,3]]])\n",
        "\n",
        "output_feature = F.max_pool2d(im, 2)\n",
        "\n",
        "print(output_feature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[6., 9.],\n",
            "         [3., 4.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVmK4uxxwOgG",
        "colab_type": "text"
      },
      "source": [
        "Оператор Max-pooling\n",
        "Здесь вы собираетесь попрактиковаться в использовании max-pooling как в ООП, так и функционально, и убедитесь, что полученные результаты одинаковы. Мы уже создали и распечатали изображение для вас, а также импортировали библиотеку torch в дополнение к torch.nn и torch.nn. Функциональные как F-пакеты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNwB069Ev9yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "max_pooling = ____\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = ____\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = ____\n",
        "\n",
        "# print the results of both cases\n",
        "print(____)\n",
        "print(____)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4AScfVZwyOq",
        "colab_type": "text"
      },
      "source": [
        "Оператор среднего пулинга\n",
        "После кодирования оператора max-pooling вы теперь собираетесь кодировать оператор среднего пула. Вам просто нужно заменить максимальный пул на средний пул."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIqxOFu0wrKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "avg_pooling = ____\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = ____\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = ____\n",
        "\n",
        "# print the results of both cases\n",
        "print(____)\n",
        "print(____)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOcWBky0wql4",
        "colab_type": "text"
      },
      "source": [
        "### 3. Convolution Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6dwQq4gx46h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes=1000):\n",
        "    \n",
        "    super(AlexNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
        "    self.relu = nn.ReLU(inplace=True) # inplace = True - x будет модифицирован напрямую и переприсвоен\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "    self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2D((6,6))\n",
        "    self.fc1 = nn.Linear(256*6*6, 4096)\n",
        "    self.fc2 = nn.Linear(4096, 4096)\n",
        "    self.fc3 = nn.Linear(4096, num_classes) \n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    x = self.relu(self.conv1(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv2(x)) # inplace = True - x будет модифицирован напрямую и переприсвоен\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv3(x)) \n",
        "    x = self.relu(self.conv4(x)) \n",
        "    x = self.relu(self.conv5(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0),256*6*6)\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "  \n",
        "  net = AlexNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iWkPEdcFeYc",
        "colab_type": "text"
      },
      "source": [
        "Ваш первый метод CNN - __init__\n",
        "Вы собираетесь построить свою первую сверточную нейронную сеть. Вы собираетесь использовать набор данных MNIST в качестве набора данных, который состоит из рукописных цифр от 0 до 9. Сверточная нейронная сеть будет иметь 2 сверточных слоя, каждый из которых сопровождается нелинейностью ReLU, и полностью связанный слой. Мы уже импортировали torch и torch.nn как nn. Помните, что каждый объединяющий слой делит пополам как высоту, так и ширину изображения, поэтому при использовании двух объединяющих слоев высота и ширина составляют 1/4 от первоначальных размеров.\n",
        "\n",
        "На данный момент вы собираетесь реализовать метод __init__ сети. В следующем упражнении вы реализуете метод .forward ().\n",
        "\n",
        "NB: не используйте inplace = True в качестве аргумента для ReLU () в строке 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEalIDIn0Fkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Instantiate two convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=____, out_channels=____, kernel_size=____, padding=____)\n",
        "        self.conv2 = ____\n",
        "        \n",
        "        # Instantiate the ReLU nonlinearity\n",
        "        self.relu = ____\n",
        "        \n",
        "        # Instantiate a max pooling layer\n",
        "        self.pool = nn.MaxPool2d(____, ____)\n",
        "        \n",
        "        # Instantiate a fully connected layer\n",
        "        self.fc = nn.Linear(____, ____)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1ZmuphgILEs",
        "colab_type": "text"
      },
      "source": [
        "Ваш первый метод CNN - forward ()\n",
        "Теперь, когда вы объявили все параметры вашего CNN, все, что вам нужно сделать, это реализовать метод forward () сети, и вуаля, у вас есть ваш самый первый PyTorch CNN.\n",
        "\n",
        "Примечание: для целей оценки весь код класса должен быть в сценарии. Мы используем метод __init__, как вы его кодировали в предыдущем упражнении, в то время как вы собираетесь кодировать метод .forward () здесь."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVn-bVORFlxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "\t\t\n",
        "        # Instantiate the ReLU nonlinearity\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # Instantiate two convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Instantiate a max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Instantiate a fully connected layer\n",
        "        self.fc = nn.Linear(7 * 7 * 10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Apply conv followd by relu, then in next line pool\n",
        "        x = self.relu(self.____)\n",
        "        x = self.pool(____)\n",
        "\n",
        "        # Apply conv followd by relu, then in next line pool\n",
        "        x = self.relu(self.____)\n",
        "        x = self.____(____)\n",
        "\n",
        "        # Prepare the image for the fully connected layer\n",
        "        x = x.view(-1, ____)\n",
        "\n",
        "        # Apply the fully connected layer and return the result\n",
        "        return self.____"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04nf6Yg0IiDb",
        "colab_type": "text"
      },
      "source": [
        "### 4. Инференс "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-xircpNInVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net  = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=3e-04)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    #Get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.view(-1, 32*32*3)\n",
        "    \n",
        "    #Zero the parameter gradient \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward + backward + optimize\n",
        "    \n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVn8-v5AJTjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct, total = 0, 0\n",
        "predictions = []\n",
        "net.eval()\n",
        "for i, data in enumerate(testloader, 0):\n",
        "  inputs, data = data\n",
        "  outputs = net(inputs)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  predictions.append(outputs)\n",
        "  total += labels.size(0)\n",
        "  correct += (predicted == labels).sum().item()\n",
        "  \n",
        "print('The testing set accuracy of the network is: %d %%' % (100*correct/total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CeJuLirJgCp",
        "colab_type": "text"
      },
      "source": [
        "Обучение CNNs\n",
        "Аналогично тому, что вы сделали в главе 2, вы собираетесь обучать нейронную сеть. Однако на этот раз вы будете тренировать CNN, созданный на предыдущем уроке, вместо полностью подключенной сети. Пакеты, которые вам нужны, были импортированы для вас, и создана сеть (называемая сетью). Также доступна функция кросс-энтропийной потери (называемая критерием) и оптимизатор Адама (называемый оптимизатором). Мы произвели субдискретизацию тренировочного набора, чтобы обучение проходило быстрее, и вы собираетесь использовать одну эпоху."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXsfG7hVJfnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterate over the data in the test_loader\n",
        "for data in ____:\n",
        "  \n",
        "    # Get the image and label from data\n",
        "    ____, ____ = data\n",
        "    \n",
        "    # Make a forward pass in the net with your image\n",
        "    output = net(____)\n",
        "    \n",
        "    # Argmax the results of the net\n",
        "    _, predicted = torch.max(____.data, 1)\n",
        "    if predicted == label:\n",
        "        print(\"Yipes, your net made the right prediction \" + str(predicted))\n",
        "    else:\n",
        "        print(\"Your net prediction was \" + str(predicted) + \", but the correct label is: \" + str(label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYPqfKNxKB7Y",
        "colab_type": "text"
      },
      "source": [
        "### 5. Sequential model\n",
        "\n",
        "Мы должны объявить каждый слой в init класса, а затем в функции forward последовательно применить их в структуре. Можно воспользоваться Sequential layer, чтобы застэкать несколько слоев вместе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6U4BWbIKZ-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes=1000):\n",
        "    \n",
        "    super(AlexNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "    self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2D((6,6))\n",
        "    self.fc1 = nn.Linear(256*6*6, 4096)\n",
        "    self.fc2 = nn.Linear(4096, 4096)\n",
        "    self.fc3 = nn.Linear(4096, num_classes) \n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    x = self.relu(self.conv1(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv2(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv3(x))\n",
        "    x = self.relu(self.conv4(x))\n",
        "    x = self.relu(self.conv5(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0),256*6*6)\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "  \n",
        "  net = AlexNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SHDkbE3K62V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "  \n",
        "  def __init__(self, num_classes=1000):\n",
        "    \n",
        "    super(AlexNet, self).__init__()\n",
        "    # feature extraction part\n",
        "    self.features = nn.Sequential(\n",
        "    nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), \n",
        "        nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.Conv2d(192, 384, kernel_size=3, padding=1), \n",
        "        nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.Conv2d(256, 256, kernel_size=3, padding=1))\n",
        "    # feature selection part\n",
        "    self.avgpool = nn.AdaptiveAvgPool2D((6,6))\n",
        "    # classification part\n",
        "    self.classifier = nn.Sequential(nn.Dropout(), nn.Linear(256*6*6, 4096), nn.ReLU(inplace=True), \n",
        "                                    nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), \n",
        "                                    nn.Linear(4096, num_classes) )\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = self.features(x)\n",
        "      x = self.avgpool(x)\n",
        "      x = x.view(-1, 256*6*6)\n",
        "      x = self.classifier(x)\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOKR9SLM8b1i",
        "colab_type": "text"
      },
      "source": [
        "Последовательный модуль - метод init\n",
        "\n",
        "Узнав о последовательном модуле, сейчас самое время посмотреть, как вы можете преобразовать нейронную сеть, которая не использует последовательные модули, в тот, который использует их. Мы даем код для построения сети обычным способом, и вы собираетесь написать код для той же сети, используя последовательные модули."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGivOMBA8U2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Declare all the layers for feature extraction\n",
        "        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels=____, out_channels=____, kernel_size=____, padding=____), \n",
        "                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(____=____, ____=____, ____=____, ____=____), \n",
        "                                      nn.ReLU(____=____),\n",
        "                                      nn.Conv2d(____=____, ____=____, ____=____, ____=____), \n",
        "                                      nn.MaxPool2d(____, ____), nn.ReLU(____=____))\n",
        "        \n",
        "        def forward(self, x):\n",
        "      \n",
        "        # Apply the feature extractor in the input\n",
        "        x = ____\n",
        "        \n",
        "        # Squeeze the three spatial dimensions in one\n",
        "        x = x.view(-1, ____ * ____ * ____)\n",
        "        \n",
        "        # Classify the images\n",
        "        x = ____\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9HvtOjVKlK9",
        "colab_type": "text"
      },
      "source": [
        "Валидация\n",
        "\n",
        "Проблема заключается в том, что наборы данных обычно не разделяются на обучение, проверку и тестирование. Ваша задача как специалиста по данным состоит в том, чтобы разделить набор данных на обучение, тестирование и проверку. Самый простой (и наиболее используемый) способ сделать это - выполнить случайное разбиение набора данных. В PyTorch это можно сделать с помощью объекта SubsetRandomSampler. Вы собираетесь разделить обучающую часть набора данных MNIST на обучение и проверку. После случайного перемешивания набора данных используйте первые 55000 баллов для обучения, а оставшиеся 5000 баллов - для проверки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdPJsMhX_rRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle the indices\n",
        "indices = np.arange(60000)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Build the train loader\n",
        "train_loader = torch.utils.data.DataLoader(datasets.MNIST('mnist', download=True, train=True,\n",
        "                     transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                     batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n",
        "\n",
        "# Build the validation loader\n",
        "val_loader = torch.utils.data.DataLoader(datasets.MNIST('mnist', download=True, train=True,\n",
        "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                   batch_size=64, shuffle=False, sampler=torch.utilds.data.SubsetRandomSampler(indices[55000:60000]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZjRSAE1BjC_",
        "colab_type": "text"
      },
      "source": [
        "### 6. Регуляризация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HICs10sfDTcW",
        "colab_type": "text"
      },
      "source": [
        "L2-регуляризация\n",
        "\n",
        "Вы собираетесь реализовать каждый из методов регуляризации, описанных в предыдущем видео. При этом вы также будете помнить важные понятия, изучаемые на протяжении всего курса. Вы начнете с l2-регуляризации, наиболее важной техники регуляризации в машинном обучении. Как вы видели в видео, l2-регуляризация просто наказывает за большие веса и, таким образом, заставляет сеть использовать только маленькие веса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4AjAAoADX7e",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1IFFVB-2wA9I8T3D3r3S7BvHVXAs9etjC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7kmqxEnDjhZ",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1Pxhw1mUp9QXIoWp8CXAwwWfvIZCFOWgv)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdcT0i8qA70U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the network\n",
        "model = Net()\n",
        "\n",
        "# Instantiate the cross-entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Instantiate the Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8y5jXU8NEHZ",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=14_sJ2S2Y-VC8OiSsJjTSYyMhW1QitYyA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL3fMrZMEcI9",
        "colab_type": "text"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "Вы видели, что dropout является эффективной техникой, чтобы избежать переобучения. Обычно дропаут применяется в полносвязанных нейронных сетях или в полносвязанных слоях сверточной нейронной сети. Теперь вы хотите реализовать dropout и использовать его в небольшой полностью подключенной нейронной сети.\n",
        "\n",
        "Для первого скрытого слоя используйте 200 единиц, для второго скрытого слоя - 500 единиц, а для выходного слоя - 10 единиц (по одному для каждого класса). Для функции активации используйте ReLU. Используйте .Dropout () с силой 0,5, между первым и вторым скрытым слоем. Используйте последовательный модуль в следующем порядке: полностью подключен, активация, выпадение, полностью подключен, активация, полностью подключен."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6JfV2HNDujN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        \n",
        "        # Define all the parameters of the net\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(28*28, 200),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(200, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(500, 10))\n",
        "        \n",
        "    def forward(self, x):\n",
        "    \n",
        "    \t# Do the forward pass\n",
        "        return self.classifier(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiiD80TzGFaX",
        "colab_type": "text"
      },
      "source": [
        "### Бэтч нормализация\n",
        "\n",
        "Дропаут используется для упорядочения полносвязанных слоев. Пакетная нормализация используется для повышения эффективности обучения сверточных нейронных сетей, в то же время обеспечивая эффект регуляризации. Вы собираетесь реализовать метод __init__ для небольшой сверточной нейронной сети с пакетной нормализацией. Часть извлечения признаков CNN будет содержать следующие модули (по порядку): conv, maxpool, relu, batchnorm, conv, maxpool, relu, batchnorm.\n",
        "\n",
        "Первый сверточный слой будет содержать 10 выходных каналов, а второй будет содержать 20 выходных каналов. Как всегда, мы собираемся использовать набор данных MNIST с изображениями, имеющими форму (28, 28) в формате градаций серого (1 канал). Во всех случаях размер фильтра должен быть 3, шаг должен быть 1, а отступ - 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEu3ci_gNaxP",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=16B6KB2j4Qr7wJrqCEt5HItZuqZjJl-eZ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUulMp-hGAia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Implement the sequential module for feature extraction\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(____, ____), nn.ReLU(inplace=____), nn.BatchNorm2d(____), \n",
        "            ____,\n",
        "            ____, ____, ____)\n",
        "        \n",
        "        # Implement the fully connected layer for classification\n",
        "        self.fc = nn.Linear(in_features=____, out_features=____)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCp_Tf6-Mz7z",
        "colab_type": "text"
      },
      "source": [
        "### Transfer Learning (перенос обучения)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIT3I6doOaMO",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1NNrBuSAIUzEsTeWeVgMtB9wKI7zZRydL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw6FEFDVPHvz",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1m13Y8HjMxwUDg4yZpkVrTlxFqHhswHwN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtAUGh2OM2os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate model\n",
        "\n",
        "model = Net()\n",
        "\n",
        "# Load parameters from the old model\n",
        "\n",
        "model.load_state_dict(torch.load(\"cifar10_net.pth\"))\n",
        "\n",
        "# Freeze all the layers except the final one\n",
        "\n",
        "for param in model.parameters():\n",
        "  \n",
        "  param.requires_grad=False\n",
        "  \n",
        "# Change the number of output units  \n",
        "\n",
        "model.fc = nn.Linear(4*4*1024, 100)\n",
        "\n",
        "# Train the model, training mode\n",
        "model.train()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUsrrQkXQYgm",
        "colab_type": "text"
      },
      "source": [
        "### Pretrained model library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYFVk_zQaCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "model.fc = Linear(512, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WpXr5nOQ7xc",
        "colab_type": "text"
      },
      "source": [
        "Fine-tuning CNN\n",
        "\n",
        "Ранее вы обучали модель классификации рукописных цифр и сохраняли параметры модели в my_net.pth. Теперь вы собираетесь классифицировать рукописные буквы, но у вас есть меньший тренировочный набор.\n",
        "\n",
        "На первом этапе вы создадите новую модель, используя этот тренировочный набор, но точность будет низкой. Далее вы проведете то же обучение, но начнете с параметров из вашей модели классификации цифр. Хотя цифры и буквы - две разные проблемы классификации, вы увидите, что использование информации из вашей предыдущей модели значительно улучшит эту."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km0EuFhfQcNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new model\n",
        "model = ____\n",
        "\n",
        "# Change the number of out channels\n",
        "model.fc = nn.Linear(7 * 7 * 512, ____)\n",
        "\n",
        "# Train and evaluate the model\n",
        "model.train()\n",
        "train_net(model, optimizer, criterion)\n",
        "print(\"Accuracy of the net is: \" + str(model.eval()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smy2R-cOQgFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model using\n",
        "model = Net()\n",
        "\n",
        "# Load the parameters from the old model\n",
        "model.____(torch.____('my_net.pth'))\n",
        "\n",
        "# Change the number of out channels\n",
        "model.fc = nn.Linear(7 * 7 * 512, 26)\n",
        "\n",
        "# Train and evaluate the model\n",
        "model.train()\n",
        "train_net(model, optimizer, criterion)\n",
        "print(\"Accuracy of the net is: \" + str(model.eval()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDQ31kR7SIXX",
        "colab_type": "text"
      },
      "source": [
        "### Модуль Torchvision\n",
        "\n",
        "На практике, однако, очень часто можно настроить CNN, которые кто-то другой (обычно разработчики библиотеки) предварительно обучил на ImageNet. Большим сетям все еще требуется много времени для обучения на больших наборах данных, и, возможно, вы не можете позволить себе обучать большую сеть на наборе данных с 1,2 миллиона изображений на вашем ноутбуке.\n",
        "\n",
        "Вместо этого вы можете просто загрузить сеть и настроить ее в своем наборе данных. Это то, что вы будете делать прямо сейчас. Предполагается, что у вас есть личный набор данных, содержащий изображения всех ваших последних 7 праздников. Вы хотите построить нейронную сеть, которая может классифицировать каждое изображение в зависимости от выходного дня. Однако, поскольку набор данных очень мал, вам необходимо использовать метод fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-2P-Y1R8Ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the module\n",
        "\n",
        "\n",
        "# Download resnet18\n",
        "model = torchvision.models.resnet18(____=____)\n",
        "\n",
        "# Freeze all the layers bar the last one\n",
        "for param in model.____:\n",
        "    param.____ = ____\n",
        "\n",
        "# Change the number of output units\n",
        "model.fc = nn.Linear(512, ____)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}